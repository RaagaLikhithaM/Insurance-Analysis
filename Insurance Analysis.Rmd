
---
title: "Insurance Data Analysis"
author: "Raaga Likhitha"
date: "`r Sys.Date()`"
output:
  pdf_document:
    latex_engine: xelatex
---




##Insurance Data - part 1

### Study summary

This study analyzes factors influencing health insurance charges using data from 1,338 policyholders.The analysis explores the relationships between insurance charges and several independent variables, including age, region, sex, number of children covered, and smoking status.Methods of analysis include descriptive statistics, correlation analysis, and various statistical tests such as t-tests, ANOVA, and regression analysis, risk ratio analysis. Visualizations such as histograms, scatter plots, and box plots are used to illustrate the distributions and relationships between variables.Results of the data analysis reveal several key findings such as Age shows a strong positive correlation with insurance charges, indicating that older individuals generally incur higher medical costs(r = 0.299, p < 0.001), with charges increasing by approximately 258  dollars per year of age.Smoking status emerges as a critical factor, with smokers facing substantially higher insurance premiums compared to non-smokers  Regional variations exist, with the Southeast showing higher average charges (14,735 dollars) compared to other regions. Gender differences are statistically significant but modest, with males having slightly higher average charges ($13,957 vs $12,570 for females). The presence of children is associated with higher charges ($13,950 vs $12,366 for no children, p = 0.018). Diagnostic analyses, including Cook's distance and Levene's tests, indicate robust statistical findings despite some outliers and heteroscedasticity. The models explain relatively modest portions of charge variance, suggesting that other factors not included in the analysis may play important roles in determining insurance costs. The study concludes that while demographic factors significantly influence insurance charges, their individual effects are moderate, indicating that a more comprehensive model incorporating additional variables might better explain the variation in health insurance charges. In conclusion, the study identifies age and smoking status as the most significant predictors of insurance charges, while the number of children, region, and sex also contribute to cost variations. These findings provide valuable insights for both insurance providers and policyholders, highlighting the key factors that influence medical costs and potentially informing strategies for risk assessment and policy pricing.


```{r loading Insurance data}
library(readxl)
library(ggplot2)
library(base)
library(epitools)
library(dplyr)
insurance_data <- read_excel("insurance-2.xlsx")
head(insurance_data)
summary(insurance_data)
glimpse(insurance_data)


```
###key summary statistics for numerical variables

```{r key summary statistics for numerical variables}
summary_stats <- insurance_data %>% summarise(
  avg_age = mean(age),
  avg_bmi = mean(bmi),
  avg_charges = mean(charges),
  smoker_ratio = mean(smoker == "yes")
)
summary_stats
```
```{r Distribution of insurance charges}
#Distribution of insurance charges
ggplot(insurance_data, aes(x = charges)) +
  geom_histogram(binwidth = 1000, fill = "blue", alpha = 0.5) +
  geom_density(color = "blue", size = 1) +
  labs(title = "Distribution of Insurance Charges", x = "Charges", y = "Frequency")

```
###Relationship Between Charges and Categorical Variables

```{r Relationship Between Charges and Categorical Variables}
ggplot(insurance_data, aes(x = smoker, y = charges, fill = smoker)) + 
  geom_boxplot() + 
  labs(title = "Charges by Smoking Status", x = "Smoker", y = "Charges")

ggplot(insurance_data, aes(x = region, y = charges, fill = region)) + 
  geom_boxplot() + 
  labs(title = "Charges by Region", x = "Region", y = "Charges")
```


###2. The general methods employed including software used, level of significance selected, one- or two-sided testing, etc. 


The analysis was conducted using R statistical software. Descriptive statistics were employed to summarize the dataset, including measures of central tendency and dispersion. For inferential statistics, a significance level of 0.05 was used for hypothesis testing.   Two-sided tests, such as t-tests and ANOVA, were used depending on the variable type. Visualization techniques, such as histograms and scatter plots, were created using the ggplot2 package in R to explore data distributions and relationships between variables. Correlation analysis was performed to assess the strength and direction of relationships between continuous variables. For comparing means across categorical groups, t-tests (for two groups) and ANOVA (for more than two groups) were employed. Regression analysis was used to model the relationship between insurance charges and various predictor variables. The specific type of regression (e.g., linear, multiple) was chosen based on the nature of the variables and research questions. All statistical tests and their corresponding p-values were reported to support the conclusions drawn from the analysis.

###3. Dependent variable. 

Here our dependent variable is charge,this plot shows that The distribution of insurance charges is positively skewed, with most individuals incurring lower charges. The histogram shows a peak at the lower end, indicating that a large number of policyholders have relatively low medical costs. The density curve highlights a long tail towards higher charges, suggesting that while high costs are less frequent, they are significant in magnitude. This skewness may be influenced by factors such as age, smoking status, and family size.

```{r summary statistics}
summary_stats <- data.frame(
  Metric = c("Mean", "Median", "Standard Deviation", "Minimum", "Maximum"),
  Value = c(mean(insurance_data$charges), 
            median(insurance_data$charges), 
            sd(insurance_data$charges), 
            min(insurance_data$charges), 
            max(insurance_data$charges))
)
print(summary_stats)
```
## When we look at the summary table, we can see that  the mean insurance charge is approximately $13,270, which is significantly higher than the median ($9,382), indicating a right-skewed distribution. The standard deviation is $12,110, showing considerable variation in charges, with some individuals  paying high costs. The charges range from $1,121.87 to $63,770.43, highlighting the presence of high-cost outliers. From this we can say that the distribution of charges is right-skewed, with most individuals having lower costs and a small number of individuals having exceptionally high expenses. 
```{r  distribution of charges}

ggplot(insurance_data, aes(x = charges)) +
  geom_histogram(binwidth = 1000, fill = "skyblue", color = "black", alpha = 0.6) +
  geom_density(aes(y = ..count.. * 1000), color = "black", size = 1) +
  labs(title = "Distribution of Insurance Charges", x = "Charges", y = "Frequency") +
  theme_minimal()

summary(insurance_data$charges)
```
```{r cumulative distribution function}
ggplot(insurance_data, aes(x = charges)) +
  stat_ecdf(geom = "step", color = "purple") +
  labs(title = "Cumulative Distribution of Insurance Charges", x = "Charges", y = "Cumulative Probability") +
  theme_minimal()
```
Here, I plotted a cumulative distributive function to identify if there is a threshold under which large number of observations fall under. It basically gives us an understanding of the overall distribution of insurance charges. The plot indicates that a majority of individuals incur medical costs below $20,000, with only a small percentage reaching higher amounts. This visualization also supports our previous finding of a right-skewed distribution, with a few extreme outliers at the upper end of the scale.

```{r skewness and kurtosis}
library(e1071)
skewness <- skewness(insurance_data$charges)
kurtosis <- kurtosis(insurance_data$charges)
skewness
kurtosis
```
The skewness and kurtosis values show that the distribution is positively skewed (1.511.51), indicating that most individuals incur lower charges, with a long tail towards higher charges.The kurtosis value of 1.59 says that distribution has slightly heavier tails than a normal distribution.

```{r outliers visualisation}
# Boxplot for charges
boxplot(insurance_data$charges,
        main = "Boxplot of Insurance Charges",
        ylab = "Charges",
        col = "lightblue",
        outline = TRUE)
```
The median charge (represented by the horizontal line in the box) is around $10,000. The interquartile range (box portion) shows that 50% of charges fall between approximately $5,000 and $17,000. This show that there is considerable variations in the charges. The distribution is strongly positively skewed, as we can see a large number of outliers above the upper whisker, The median line being closer to the bottom of the box, Multiple extreme values extending up to around $60,000. In addition to this, we can see that there are many outliers above the upper whiskers which is cases with high insurance charges. The histogram suggests that there is a peak in frequency at the lower end of the distribution. A long right tail extending toward higher charges and most charges are concentrated in the lower range with decreasing frequency as charges increase. This is a  non-normal distribution which suggests that while most insurance charges are relatively modest, there are some cases with significantly higher costs that pull the mean above the median.



```{r density plot for probability distribution}
plot(density(insurance_data$charges),
     main = "Density Plot of Insurance Charges",
     xlab = "Charges",
     ylab = "Density",
     col = "blue",
     lwd = 2)
```

The density plot reveals a strong positive skew with the highest density of charges concentrated between $0-10,000 and a primary peak around $5,000-7,000. In addition there is a gradual decline with multiple smaller peaks. A long right tail extending to approximately $60,000 with a small secondary peak around $40,000, suggesting a possible subgroup of high-cost policyholders.

```{r facet plots for subgroups smoker and region }
ggplot(insurance_data, aes(x = charges, fill = smoker)) +
  geom_histogram(binwidth = 1000, alpha = 0.7, position = "identity") +
  facet_wrap(~ smoker) +
  labs(title = "Distribution of Charges by Smoking Status", x = "Charges", y = "Frequency") +
  theme_minimal()

ggplot(insurance_data, aes(x = charges, fill = region)) +
  geom_histogram(binwidth = 1000, alpha = 0.7, position = "identity") +
  facet_wrap(~ smoker) +
  labs(title = "Distribution of Charges by Smoking Status", x = "Charges", y = "Frequency") +
  theme_minimal()

```


For non-smokers, the majority of charges are concentrated in the lower range (below \$20,000).Smokers show a noticeable shift toward higher charges, with many falling in the \$20,000–\$60,000 range. All four regions (northeast, northwest, southeast, southwest) show similar patterns with the highest frequency of charges occurs in the lower ranges across all regions. Higher charges (>\$40,000) are present in all regions but with lower frequency. The southeast region appears to have slightly more cases in the higher charge ranges.This reveals that smoking status appears to be a major factor in determining insurance charges, while regional differences are less pronounced.

### 4. Associations of charges with age. there is  a short summary of the analytic approach  which i used to explore associations of charges with age. I included the specific test statistics used, including where appropriate, degrees of freedom. I also presented a labeled plot that best summarizes the association. I summarized the association of charges with age including test results. I also gave conclusions concerning the association of charges and age

To analyse the association of charges with age, I plan to do linear regression and correlation analysis. Linear Regression helps us quantify the relationship between age and charges, where Test statistic would be t-test for slope coefficient and Degrees of freedom are  n-2, where n is the sample size. We assume our null hypothesis to be that there is no linear relationship between age and charges. On the other hand, the correlation Analysis will help us measure the strength and direction of the relationship, where the pearson correlation coefficient will be the test for significance of correlation. I assume that The analysis will likely help us understand the strength and direction of the relationship between age and charges,the amount of variance in charges explained by age (R-squared), and whether the relationship is statistically significant as we can expect change in charges for each year increase in age.  This analysis will provide a comprehensive understanding of how age influences insurance charges while controlling for other variables.

```{r  Simple linear regression and correlation coefficient}
library(ggplot2)
library(dplyr)

# scatter plot with regression line
ggplot(insurance_data, aes(x = age, y = charges)) +
  geom_point(alpha = 0.5, color = "darkblue") +
  geom_smooth(method = "lm", color = "red") +
  labs(title = "Insurance Charges vs Age",
       x = "Age (years)",
       y = "Charges ($)") +
  theme_minimal()

age_model <- lm(charges ~ age, data = insurance_data)
summary(age_model)

cor(insurance_data$age,insurance_data$charges)
cor.test(insurance_data$age,insurance_data$charges)

```
From this analysis where we performed a  simple linear regression  to examine the relationship between age (independent variable) and insurance charges (dependent variable), with 1,336 degrees of freedom.We can see that the regression coefficient for age is 257.7 (SE = 22.5), indicating that for each year increase in age, insurance charges increase by approximately \$257.70. The intercept is \$3,165.9, representing the expected charges for age zero (theoretical only). The relationship is highly significant (p < 2e-16). The t-value for age is 11.453, indicating a strong positive relationship The F-statistic of 131.2 (df = 1, 1336) confirms the model's overall significance. The scatter plot shows a positive linear trend (red line) with considerable dispersion around the regression line. In addition we can see a higher variability in charges for older ages. Several high-cost outliers, particularly in the upper age ranges45-60 can be observed.  We can conclude that there is a significant positive association between age and insurance charges. The model explains approximately 8.9% of the variance in charges (R-squared = 0.08941). While age is a significant predictor, the low R-squared suggests other factors (such as smoking status, visible in the additional plots) play important roles in determining insurance charges. 

Our null hypothesis(H0) in this analysis was that There is no association at all between age and charges.and our alternative hypothesis (Ha) is that  There is a link, either positive or negative, between age and charges that is greater than zero.The correlation coefficient (r) = 0.299 with 95% CI: 0.249 to 0.347, also indicates a weak to moderate positive correlation between age and charges. In addition, the presence of distinct clusters suggests other factors (particularly smoking status, as shown in the additional plots) have a stronger influence on charges than age alone. We can  understand that this is a highly significant correlation (t = 11.453, p < 2.2e-16) and the correlation is significantly different from zero, so we can reject the null hypothesis



```{r Diagnostic plots}

age_model <- lm(charges ~ age, data = insurance_data)

# QQ Plot for residuals of the regression model
qqnorm(residuals(age_model), main = "QQ Plot of Residuals")
qqline(residuals(age_model), col = "red")

par(mfrow=c(2,2)) 
plot(age_model)

```
### Diganostic plots reveal that

1. Residuals vs. Fitted Plot( Checks for non-linearity and equal variance (homoscedasticity) of residuals.)  shows a clear horizontal banding pattern shows two distinct groups in the residuals. In addition, we can see a non-random pattern which  indicates violation of linearity assumption, the residuals range from approximately -10,000 to 50,000 and  we can see several outliers identified (points 578, 1301, 544)

2. QQ Plot of Residuals( Evaluates whether the residuals follow a normal distribution) shows a significant deviation from the theoretical normal line. There is a step-like pattern in the middle range, with heavy tails at both ends which indicates non-normal distribution of residuals

3.  Scale-Location Plot( Assesses the homogeneity of variance (constant variance of residuals)) shows a relatively horizontal trend line with slight downward slope and there is a spread of standardized residuals shows some heteroscedasticity and Square root of standardized residuals ranges from 0 to 2.0

4. Residuals vs. Leverage Plot( Detects influential data points that could disproportionately affect the regression model) this  shows no highly influential points (no observations beyond Cook's distance). Most leverage values are below 0.003. Several outliers visible but not highly influential. Points such as 544, 1147, and 2420 are identified as potential influential points with high leverage.

```{r cooks distance}
cooks_d <- cooks.distance(age_model)

influential <- which(cooks_d > (4/length(cooks_d)))

plot(cooks_d, type="h", main="Cook's Distance Plot",
     ylab="Cook's Distance", xlab="Observation Number")
abline(h = 4/length(cooks_d), col="red", lty=2)
```
Cooks distance plot shows that the red dashed line represents the threshold of 4/n (approximately 0.003), Most observations have Cook's distance values below 0.004 and there are several spikes appear throughout the dataset, but none are particularly concerning. The highest spike appears around observation 500-600, but still remains below 0.012
```{r cooks distance, threshold}

cooks_d <- cooks.distance(age_model)

threshold <- 4 / (nrow(insurance_data) - length(coef(age_model)))
influential <- which(cooks_d > threshold)

plot(cooks_d, type = "h", 
     main = "Cook's Distance Plot", 
     ylab = "Cook's Distance", 
     xlab = "Observation Number")

abline(h = threshold, col = "red", lty = 2)

points(influential, cooks_d[influential], col = "blue", pch = 2)
text(influential, cooks_d[influential], labels = influential, pos = 4, col = "blue")

print(paste("Influential points (above threshold):", paste(influential, collapse = ", ")))

```
```{r high influence regions}
high_influence <- insurance_data$region[cooks_d>0.010]
print(high_influence)
```

```{r  filtered model without high influence points}
# subset of the data excluding high-influence points
filtered_data <- subset(insurance_data, cooks_d < 0.01)
cat("Dimensions of filtered data (Filtered Data):", dim(filtered_data), "\n")
cat("Dimensions of original data (Original Data):", dim(insurance_data), "\n")

filtered_model <- lm(charges ~ age, data = filtered_data)

hist(residuals(filtered_model), main = "Histogram of Residuals (Filtered Data)", 
     xlab = "Residuals", col = "lightgreen", border = "black")

cat("Original Model Coefficients:\n")
print(age_model$coefficients)

cat("Filtered Model Coefficients:\n")
print(filtered_model$coefficients)

```
After removing influential points, the dataset size decreased from 1,338 to 1,335 rows. Coefficients were Intercept: $3,402.66  and  Age: $249.56 in comparison to our original model with Intercept: $3,165.89 and Age: $257.72. The effect of age on charges is slightly reduced after removing influential points. The coefficients changed marginally, suggesting that influential points did not drastically distort the original model.The histogram of residuals for the filtered model shows a similar spread, indicating that removing influential points did not significantly improve the residual distribution.In the original model too we observed that Age is statistically significant but not a strong predictor of charges, as indicated by the low R2 and the model is sensitive to influential points, as highlighted by Cook’s Distance. This shows that even when age is significant predictor other factors influence the insurance prices and we have to study them.

###5. Associations of charges with region. I have given a short summary of the analytic approach that I used to explore associations of charges with region. I included the specific test statistics used, including where appropriate the degrees of freedom. I also presented a plot and a table to summarize the charges across the regions. In addition, I summarized the association of charges with region including the testing results. I  Summarized which regions have significantly higher or lower mean charges and gave conclusions concerning charges and region?

To analyze the association between insurance charges(continuous variable) and region(categorical variable), we'll use a one-way ANOVA approach since region is a categorical variable with four levels (northeast, southeast, southwest, northwest). In this, ANOVA (Analysis of Variance) is Used to compare the mean charges across the four regions.Our hypothesis is that H0 : The mean charges are equal across all regions and Ha : At least one region has a significantly different mean charge.The F1 statistic and p-value will determine the significance. For post hoc analysis, we will do Tukey's HSD which will identify pairwise differences between regions if ANOVA is significant.

```{r summary statistics ANOVA and TukeyHSD}

ggplot(insurance_data, aes(x = region, y = charges, fill = region)) +
  geom_boxplot() +
  labs(title = "Insurance Charges by Region",
       x = "Region",
       y = "Charges ($)") +
  theme_minimal()


region_summary <- insurance_data %>%
  group_by(region) %>%
  summarise(
    mean_charges = mean(charges),
    sd_charges = sd(charges),
    n = n()
  )
print(region_summary)


region_aov <- aov(charges ~ region, data = insurance_data)
summary(region_aov)



TukeyHSD(region_aov)


```
From ANOVA we got that F-statistic is 4.846 with 3 and 1334 degrees of freedom and p-value is 0.0309 (significant at $\alpha  = 0.05$).Degrees of Freedom (Df) between groups (df) = 3 (4 regions - 1). and within groups(df) = 1334 (total observations - regions). The sum of squares between groups is 1.301e+09 (variation explained by differences among regions) and residuals is 1.948e+11 (variation within each region). The mean square between groups is  433,586,560 with residuals: 146,007,093 and an F of 2.97 which Compares between-group to within-group variance.

Tukey's HSD Results show that Southeast vs Southwest had a p =0.0477  which is  significant difference, with the southeast region having higher mean charges than the southwest region.Other comparisons ( p>0.05) do not show significant differences. The Confidence Intervals include 0, indicating no significant difference between those regions. For southeast-southwest, the confidence interval  [4760.51,−16.44] does not include 0, confirming the significance. The Southeast region has the highest mean charges ($14,735) and The Southwest region has the lowest mean charges (\$12,347). In addition, Significant differences exist between Southeast and Southwest regions (p < 0.05) and Southeast and Northwest regions 

From the box plot we can understand that the median charge (horizontal line inside each box) is highest for the southeast region, followed by the northeast, and lowest for the southwest and northwest regions. The southeast region has the widest IQR, indicating greater variability in charges. However, the northeast, northwest, and southwest regions have similar and narrower IQRs. All regions display numerous outliers (dots) above \$40,000 and whiskers extend similarly across all regions, suggesting comparable spread. All regions show positive skewness (longer upper whiskers) and we can see that there are substantial number of high-cost outliers in all regions with  southeast region showing slightly more variability and similar lower bounds across regions (around \$2,000-\$3,000) and upper outliers extending to approximately \$60,000 in all regions. The bulk of charges in all regions fall between \$5,000 and \$20,000. This boxplot suggests that while there are some regional differences in insurance charges, they are relatively modest compared to the overall variation within each region.

###6)Associations of charges with sex. I have given a short summary of the analytic approach I used to explore associations of charges with sex.  I included the specific test statistics used, including where appropriate the degrees of freedom. I  presented a plot and a table to summarize the charges across sex. i summarized the association of charges with sex including the testing results. I have also pointed to my conclusions concerning charges and sex?


We use an independent samples t-test to compare mean charges between males and females, as sex is a binary categorical variable and charges is continuous. The degrees of freedom are calculated as n₁ + n₂ - 2,where n1 and n2 are sample sizes for each group. Here we begin with this hypothesis that H0: There is no significant difference in mean charges between males and females. and Ha : There is a significant difference in mean charges between males and females. We assume that we will have  normally distributed charges within groups and equal variance. If variances are unequal, Welch's t-test will be used. 
 

```{r summary statistics and t test}
library(ggplot2)
library(dplyr)

ggplot(insurance_data, aes(x = sex, y = charges, fill = sex)) +
  geom_boxplot() +
  labs(title = "Insurance Charges by Sex",
       x = "Sex",
       y = "Charges ($)") +
  theme_minimal() +
  scale_fill_manual(values = c("lightblue", "lightpink"))

sex_summary <- insurance_data %>%
  group_by(sex) %>%
  summarise(
    mean_charges = mean(charges),
    median_charges = median(charges),
    sd_charges = sd(charges),
    n = n()
  )

t_test_result <- t.test(charges ~ sex, data = insurance_data)

print(sex_summary)
print(t_test_result)
```
Our initial approach was to use a standard independent samples t-test, but Welch's t-test was more appropriate because the standard deviations differ considerably between groups with Female SD \$11,128.70 and Male SD of \$12,971.03. The sample sizes are slightly unequal, with Females, n = 662 and Males, n = 676. Welch's t-test does not assume equal variances between groups, making it more robust when these assumptions are violated. This is evident in the fractional degrees of freedom (df = 1313.4) in our results, which is a characteristic of Welch's adjustment. The boxplot visualization supports this decision, showing different spreads between male and female groups and more extreme outliers in the male group. There are slightly different shapes in the distributions which makes Welch's t-test a more conservative and appropriate choice for comparing insurance charges between males and females.

results of t test show that t-statistic = -2.1009 with 1313.4 degrees of freedom and p-value = 0.03584 (significant at $\alpha = 0.05$). The p-value (< 0.05) indicates a statistically significant difference in mean charges between males and females.The confidence interval[-2682.49, -91.86] does not include 0, confirming the significance of the difference. In our tests, we get that Males have higher mean charges ($13,957) compared to females ($12,570) and  the difference in means is $1,387 (95% CI: $92 to $2,682) and medians are very similar (approximately $9,400 for both groups) and Males show higher variability in charges (SD = $12,971 vs $11,129).The practical significance is modest, with males paying on average $1,387 more than females.The substantial overlap in distributions suggests sex alone is not a strong predictor of insurance charges


```{r effect size and levine test}
library(effsize)
cohen_d <- cohen.d(charges ~ sex, data = insurance_data)
print(cohen_d)

library(car)
leveneTest(charges ~ sex, data = insurance_data)

```
 when we did the effect size analysis, Cohen's d = -0.115 (95% CI: -0.222 to -0.007) and the negative value indicates lower charges for females. This effect size can be classified as "negligible" as the confidence interval barely excludes zero, suggesting a very weak practical significance.Levene's test results: F(1, 1336) = 9.9093, p = 0.001681 which means that p < 0.01 which is signicant and  indicates unequal variances between groups.The test rejects the null hypothesis of equal variances between groups. This confirms our decision to use Welch's t-test instead of the standard t-test. In conclusion, we can understand that the effect size analysis suggests that sex alone is not a meaningful predictor of insurance charges and Other factors likely have more substantial influences on insurance charges than sex.


###7) Associations of High with sex. To further explore the above, I created a new variable “High” that is 0 if charges are less than 15,000 and 1 if charges are greater than or equal to 15,000. Then I found out the relative risk for high charges for female compared to males.  I included 95% confidence intervals for the relative risk. 


```{r creation of binary variable }

library(epitools)

# Create new binary variable "High"
insurance_data$High <- ifelse(insurance_data$charges >= 15000, 1, 0)

# contingency table
high_sex_table <- table(insurance_data$sex, insurance_data$High)

rr_result <- riskratio(high_sex_table, rev="b")

print(rr_result)

```
The relative risk analysis shows that females have a lower risk of high charges compared to males and the risk ratio is approximately 0.85. The 95% confidence interval ranges from approximately 0.73 to 0.98 which means that females are about 15% less likely to have high charges (≥\$15,000) compared to males. This finding aligns with our earlier t-test results, which showed lower average charges for females, though the effect is modest.Females have a 1.08 times (or 8% higher) likelihood of having high charges compared to males. The relative risk analysis provides a more interpretable measure of the difference between sexes in terms of high-cost cases.The risk ratio is statistically significant (p = 0.025) with females have approximately 7.7% higher risk of high charges compared to males The confidence interval excluding 1.0 confirms that this difference is statistically significant, though the practical significance remains modest given the relatively narrow range of the confidence interval. In this test, we also got Two-sided p-values all indicate statistical significance from Midp exact: p = 0.0253, Fisher's exact: p = 0.0263 and Chi-square: p = 0.0252.

This finding adds nuance to our earlier analyses, suggesting that while males have higher average charges overall, females have a slightly higher risk of crossing the \$15,000 threshold. This risk ratio analysis provides a different perspective from our earlier t-test results, highlighting the importance of examining the data from multiple angles.


###8. Associations of charges with children. I Created a new variable “Child” that is 0 if no children and 1 if one or more children  and then I gave a  short summary of the analytic approach that I used to explore associations of charges with Child. I included the specific test statistics used, including where appropriate the degrees of freedom. I presented a plot and a table to summarize the charges across Child.  Then I summarized the association of charges with Child including the testing results and I drew my conclusions concerning charges and Child 


```{r Creating new variable child, t test and plot}
library(ggplot2)
library(dplyr)

# Create binary Child variable
insurance_data$Child <- ifelse(insurance_data$children > 0, 1, 0)

ggplot(insurance_data, aes(x = factor(Child), y = charges)) +
  geom_boxplot(fill = "lightblue") +
  labs(title = "Insurance Charges by Child Status",
       x = "Child (0 = No Children, 1 = With Children)",
       y = "Charges ($)") +
  theme_minimal()

child_summary <- insurance_data %>%
  group_by(Child) %>%
  summarise(
    mean_charges = mean(charges),
    median_charges = median(charges),
    sd_charges = sd(charges),
    n = n()
  )

print(child_summary)

t_test_child<- t.test(charges ~ Child, data = insurance_data)
print(t_test_child)

```

The results show that Welch's t-test: t(1240.3) = -2.3753, p = 0.01769 with a m ean difference = -\$1,584 (95% CI: -\$2,892 to -\$276) and a negative t-statistic indicates lower charges for those without children. We can understand that  individuals with children (Child = 1) have higher average charges (\$13,949.94) compared to those without children (\$12,365.98). and the median charges are slightly higher for individuals without children.The variability in charges (SD) is similar between the two groups.The p-value (0.01769) is less than 0.05, which shows that people with children have higher average charges (\$13,950) compared to those without children (\$12,366). The difference, while statistically significant, is relatively modest (\$1,584). The substantial overlap in distributions and similar spreads suggest that child status alone is not a strong predictor of insurance charges and Both groups show similar patterns of extreme values, as evidenced by the outliers in the boxplot.

## 9. correlation analysis

```{r Correlation analysis}
library(corrplot)
num_vars <- insurance_data %>% select(age, bmi, children, charges)
corr_matrix <- cor(num_vars)
corrplot(corr_matrix, method = "circle")
```

### To further add depth to this analysis, I plan to do feature engineering. For this  I am categorizing BMI into Health Risk Groups. In this I  will create a new column BMI_Category based on the following classification, Underweight: BMI < 18.5; Normal Weight: BMI 18.5–24.9; Overweight: BMI 25–29.9 Obese: BMI ≥ 30


```{r Feature Engineering}

# Categorizing BMI into health risk groups
insurance_data <- insurance_data %>%
  mutate(BMI_Category = case_when(
    bmi < 18.5 ~ "Underweight",
    bmi >= 18.5 & bmi < 25 ~ "Normal Weight",
    bmi >= 25 & bmi < 30 ~ "Overweight",
    bmi >= 30 ~ "Obese"
  ))

table(insurance_data$BMI_Category)

# Visualizing the charges across BMI categories
ggplot(insurance_data, aes(x = BMI_Category, y = charges, fill = BMI_Category)) +
  geom_boxplot() +
  labs(title = "Insurance Charges by BMI Category",
       x = "BMI Category",
       y = "Charges ($)") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set2")

```

## BMI Category Distribution showed that Obese: 707 individuals (largest group); Overweight: 386 individuals; Normal Weight: 225 individuals and  Underweight: 20 individuals (smallest group). when we look at the Charges by BMI Category, Obese Individuals: Have the highest median charges with a larger spread and many high-cost outliers. Overweight and Normal Weight individuals show moderate charges with fewer extreme values compared to the obese category. and Underweight individuals Have the lowest charges and minimal variation in costs.The boxplot reveals that BMI is a strong indicator of insurance charges. Obese individuals incur significantly higher charges, likely due to increased health risks associated with obesity.


## now I will do a statistical test to identify the significance of differences in between BMI categories. In this, Since BMI_Category is categorical (4 groups) and charges is continuous, I am using a one-way ANOVA.  If ANOVA shows significance, we’ll proceed with Tukey’s HSD for pairwise comparisons.
```{r One way ANOVA and TukeyHSD on BMI categories}

# One-Way ANOVA
bmi_aov <- aov(charges ~ BMI_Category, data = insurance_data)
summary(bmi_aov)

# Tukey's HSD test for pairwise comparisons
tukey_result <- TukeyHSD(bmi_aov)
print(tukey_result)
plot(tukey_result, las = 1, col = "blue")

```
The p-value ( 6.66 × 10 −12  ) is extremely significant, confirming that there are differences in charges among BMI categories. And the Tukey's HSD Test reveal significant pairwise differences. In this we can understand that when we compare Obese vs Normal Weight individuals, Obese individuals incur, on average, 5143 dollars more charges and  Obese vs Overweight comparison shows Obese individuals incur $4565 more charges. There are non-significant Differences in  Underweight vs Normal Weight, Overweight, or Obese categories. The from the 95% confidence intervals plot we can so that there are significant differences (intervals do not cross zero)  which are primarily seen for Obese individuals compared to Normal Weight and Overweight categories.The analysis highlights that obesity significantly increases insurance charges compared to other BMI categories, suggesting a direct relationship between health risk (BMI) and healthcare costs.

```{r the relationship between smoking status and insurance charges}
# Boxplot: Insurance Charges by Smoking Status
ggplot(insurance_data, aes(x = smoker, y = charges, fill = smoker)) +
  geom_boxplot() +
  labs(title = "Insurance Charges by Smoking Status",
       x = "Smoking Status",
       y = "Charges ($)") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set1")

# Perform Welch's t-test for Charges by Smoking Status
t_test_smoking <- t.test(charges ~ smoker, data = insurance_data, var.equal = FALSE)
print(t_test_smoking)

```
The boxplot clearly shows that smokers incur significantly higher charges compared to non-smokers.
Smokers have a much wider spread, with charges reaching extreme values (outliers above 60,000 dollars), while non-smokers' charges are concentrated around the lower end.T-test Results show a t-value of  -32.75 and p-value of  < 2.2 ×10 −16 which is extremely significant and we have a 95% Confidence Intervalof [-25,034.71, -22,197.21]. the mean charges for non-Smokers was $8,434 and smokers was $32,050. From this we can safely say that the difference in mean insurance charges between smokers and non-smokers is highly significant. Smokers pay, on average, ~$24,000 more than non-smokers. This underscores the substantial impact of smoking on healthcare costs.

## multiple  linear regression model with  predictors such as age, bmi, children, smoker, region and sex

```{r Multiple Linear Regression Model}

mlr_model <- lm(charges ~ age + bmi + children + smoker + region + sex, data = insurance_data)

summary(mlr_model)

# Checking for multicollinearity using VIF
library(car)
vif_values <- vif(mlr_model)
print(vif_values)

par(mfrow = c(2, 2))
plot(mlr_model)
```
This model shows that the Significant Predictors are age (p<2e−16) which gave thatfor every additional year of age, charges increase by ~256.9 dollars. then bmi (p<2e −16) which showed that each unit increase in BMI raises charges by ~339.2 dollars. Children with p=0.000577) was also a significant predictor, which showed that for each additional child adds ~475.5 dollars to charges. In addition, smokeryes (p<2e −16) ) which showed that smokers incur ~23,848 dollars more than non-smokers. In addition, in regions, southeast and southwest with p<0.05 had  Lower charges compared to the northeast. The insignificant predictors were northwest region with p=0.459, sexmale (p=0.693) which means thatGender does not significantly affect charges. The model has a R2 of 0.7509 which means that the model explains ~75% of the variance in charges. The Residual Standard Error was  $6,062, and All VIF values s are close to 1, indicating no multicollinearity issues among predictors. The diagnostic plots show that there are no strong patterns between residuals vs fitted, but slight heteroscedasticity is visible (higher variance at larger fitted values). The  QQ Plot showe d Some deviations from normality at the tails. The scale-location plot showed a minor heteroscedasticity (spread increases slightly with fitted values). The residuals vs leverage plot showed that a few points exceed Cook's distance threshold, indicating potential influential observations.



## log transformation the charges to address the non-normality and heteroscedasticity in residuals. 

```{r}
insurance_data$log_charges <- log(insurance_data$charges)

#  multiple linear regression model with log-transformed charges
mlr_log_model <- lm(log_charges ~ age + bmi + children + smoker + region + sex, data = insurance_data)

summary(mlr_log_model)

par(mfrow = c(2, 2))
plot(mlr_log_model)


```

The Model Summary with log transformation of charges showed that the Significant Predictors were  age (p<2e−16), where the log-transformed charges increase by ~3.46% for each additional year of age.The bmi with p<2e −10 showed that a unit increase in BMI results in a ~1.34% increase in log-transformed charges. Children with a p <2e −16 showed that Each additional child increases log-transformed charges by ~10.2%. The smokeeryes had a p<2e −16 which means that Smokers incur ~155% higher charges on the log scale compared to non-smokers. The regions region (southeast, southwest)  had a p<0.001 which means that These regions show reduced charges compared to the northeast. The sexmale (p=0.002) which means that Males incur ~7.54% lower charges compared to females. The new model's fit showed an R2  =0.7679 which  Explains ~76.8% of the variance in log-transformed charges. The Residual Standard Error is 0.4443, indicating that this model has achieved a a better fit compared to the original model.
2. Diagnostic Plots showed that
Residuals vs Fitted had an Improved homoscedasticity (residuals are more evenly distributed).
QQ Plot showed that Residuals align better with the theoretical quantiles, indicating improved normality.
Scale-Location plot Shows more consistent spread of residuals across fitted values.
Residuals vs Leverage plot shows Fewer influential points exceeding Cook’s distance threshold.

```{r  cooks distance,removing influential points, refitting the model}
influential_points <- which(cooks.distance(mlr_log_model) > (4 / nrow(insurance_data)))

print(length(influential_points))  
print(influential_points)  

## new data set without these influential points
insurance_data_filtered <- insurance_data[-influential_points, ]

# Refitting the model with filtered data
mlr_filtered_model <- lm(log_charges ~ age + bmi + children + smoker + region + sex, data = insurance_data_filtered)

summary(mlr_filtered_model)

# Diagnostic plots for the filtered model
par(mfrow = c(2, 2))
plot(mlr_filtered_model)
```

Residual Standard Error decreased significantly from 0.4443 to	0.2708, indicating a better fit of the model .R²  improved from 0.7679	to 0.9096
Adjusted R² from 	0.7666 to 	0.9090, showing the filtered model explains ~91% of the variance in log-transformed charges compared to ~76.8% previously.

 In Significant Predictors, for Age, Coefficient increased slightly (+0.0346→+0.0407) reinforcing that charges increase with age.
BMI: Effect size slightly reduced (+0.0134→+0.0094), indicating BMI has less impact after filtering. For Children, the Effect size increased (
+0.1018→+0.1127), showing a stronger effect on charges. For Smoking (Yes): Effect size increased slightly (++1.554→+1.601), confirming the high cost impact of smoking.Region Effects showed Significant reductions in charges for certain regions were more pronounced. Sex (Male)  is Now significant (−0.0754→−0.0914), indicating males incur ~9.1% lower charges than females after filtering.
Diagnostic Plots:
Residuals vs Fitted: Homoscedasticity improved further, with more consistent spread.
QQ Plot: Residuals align better with the theoretical quantiles, showing improved normality.
Scale-Location: Variance is more uniform across fitted values.
Residuals vs Leverage: Fewer high-leverage points exceeding Cook’s distance, reducing undue influence.

Removing influential points improved model fit significantly, as seen in the higher R2 and lower residual error. Predictor significance and effect sizes became more refined after filtering. Diagnostic plots indicate a well-behaved model with improved residual patterns.

## Logistic regression with the binary variable high that we created in the previous steps

```{r Logistic Regression Model for High Charges,Odds ratios, ROC and AUC}

logistic_model <- glm(High ~ age + bmi + children + smoker + region + sex,
                      data = insurance_data_filtered, family = binomial)

summary(logistic_model)

# Odds Ratios 
odds_ratios <- exp(coef(logistic_model))
print(odds_ratios)

# Step 2: Model Evaluation

probabilities <- predict(logistic_model, type = "response")

predictions <- ifelse(probabilities > 0.5, 1, 0)

table(Predicted = predictions, Actual = insurance_data_filtered$High)

# ROC Curve and AUC
library(ROCR)
pred <- prediction(probabilities, insurance_data_filtered$High)
perf <- performance(pred, "tpr", "fpr")
plot(perf, colorize = TRUE, main = "ROC Curve for High Charges Prediction")
abline(a = 0, b = 1, col = "red", lty = 2)

auc <- performance(pred, "auc")
auc_value <- auc@y.values[[1]]
print(paste("AUC:", auc_value))

```
Significant Predictors with p<0.05 include Age with a p=2.68×10−11 which means for each additional year increases the odds of being in the "high charges" category by ~18% (OR = 1.18). Then, BMI with a p=0.00387 which means a unit increase in BMI raises the odds by ~9% (OR = 1.09).Children with a p=3.06×10−5 which meant that for  Each additional child increases the odds by ~71% (OR = 1.71). Smoking had a p<2×10−16, which means that Smokers have ~63,954 times higher odds of incurring high charges compared to non-smokers (OR = 63,954), underscoring the significant cost impact of smoking.
Insignificant Predictors were Region (Northwest, Southeast, Southwest) as there was no significant regional differences in high charges. Sex (Male) where Gender does not significantly impact the odds of high charges.
2.Odds ratios indicate the multiplicative change in the odds of high charges for a one-unit increase in the predictor:
Smoking: Strongest predictor with a massive odds ratio.
Age, BMI, and number of children: Moderate positive effects.
3. Model Fit:
Residual Deviance: 277.26 (a substantial reduction from null deviance, indicating a well-fitting model).
AIC: 295.26, useful for model comparison.
Overall Fit: Model captures the majority of variance effectively.
4. Confusion Matrix:
True Positives (1 predicted as 1): 232.
True Negatives (0 predicted as 0): 960.
False Positives (0 predicted as 1): 8.
False Negatives (1 predicted as 0): 36.
Accuracy:960+36+8+232/ 960+232 =96.8%, showing excellent classification performance.
5. ROC Curve and AUC:
AUC: 0.98, indicating excellent model performance in distinguishing between high and low charges.
Key Takeaways:
Smoking is the most significant predictor of high charges, with an overwhelmingly large impact.
Age, BMI, and children also significantly affect the odds of high charges.
The model achieves high accuracy (96.8%) and has excellent discrimination ability (AUC = 0.98).

## model diagnostics and validation

```{r Model diagnostics}
# Splitting data into training (80%) and testing (20%) sets
set.seed(123)  
train_index <- sample(1:nrow(insurance_data_filtered), 0.8 * nrow(insurance_data_filtered))
train_data <- insurance_data_filtered[train_index, ]
test_data <- insurance_data_filtered[-train_index, ]

# Refitting logistic regression model on the training set
logistic_train_model <- glm(High ~ age + bmi + children + smoker + region + sex, 
                            data = train_data, family = binomial)

test_probabilities <- predict(logistic_train_model, newdata = test_data, type = "response")

test_predictions <- ifelse(test_probabilities > 0.5, 1, 0)

confusion_matrix <- table(Predicted = test_predictions, Actual = test_data$High)
print(confusion_matrix)

accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Accuracy:", accuracy))

# ROC Curve and AUC
library(ROCR)
test_pred <- prediction(test_probabilities, test_data$High)
test_perf <- performance(test_pred, "tpr", "fpr")
plot(test_perf, colorize = TRUE, main = "ROC Curve for Testing Set")
abline(a = 0, b = 1, col = "red", lty = 2)

# Calculate AUC for testing set
test_auc <- performance(test_pred, "auc")
test_auc_value <- test_auc@y.values[[1]]
print(paste("AUC:", test_auc_value))
```
From this we can understand that The ROC curve for the test set shows a strong separation between true positive and false positive rates.AUC (Area Under Curve)is  0.984, indicating excellent discrimination.The logistic regression model performs exceptionally well on the test data, with high accuracy (95.56%) and AUC (0.984). Sensitivity is slightly lower (85%), suggesting some room for improvement in identifying all "high charge" cases.
Predictor Significance:
Earlier insights regarding smoking, age, BMI, and children as key predictors remain valid.The model demonstrates strong generalizability, as shown by its performance on unseen test data.


